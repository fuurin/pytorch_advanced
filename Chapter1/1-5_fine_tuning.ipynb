{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ファインチューニングの実装\n",
    "- GPUの使用\n",
    "- ファインチューニング\n",
    "- パラメータの保存/読み出し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWSクラウドGPUの使用方法\n",
    "強いEC2立ててそこで動かすだけなのでここに追記  \n",
    "  \n",
    "GPUマシンとしては`p2.xlarge`を用いる．  \n",
    "一番安価な強力GPUマシン  \n",
    "料金は約100円/hour(米国サーバなら)  \n",
    "メモリサイズは約64GB  \n",
    "ストレージは75GBだが，必要に応じて200GBなどに増やす  \n",
    "あとはサーバー立てたらSSH接続して環境整えてリポジトリもらって実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ファインチューニング\n",
    "転移学習では一部のみに対して再学習させたり，モデルへの変更を加えたりした．  \n",
    "対してファインチューニングは，全ての層のパラメータを再学習させる  \n",
    "入力層に近い所は学習率を小さく，出力層に近い所は大きくするのが一般的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## フォルダ準備と事前準備\n",
    "1-1のフォルダ準備を行う  \n",
    "また，GPUマシン上で学習を実行する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DatasetとDataLoaderを作成\n",
    "1-3の\n",
    "- ImageTransform\n",
    "- make_datapath_list\n",
    "- HymenpopteraDataset\n",
    "\n",
    "を再利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../datasets/ptca_datasets/chapter1\"\n",
    "hymenoptera_path = os.path.join(data_dir, \"hymenoptera_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \"\"\"\n",
    "    画像の前処理＋DataAug\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    resize: int\n",
    "        リサイズ先の大きさ\n",
    "    mean: (R, G, B)\n",
    "        各色チャネルの平均値\n",
    "    std: (R, G, B)\n",
    "        各色チャネルの標準偏差\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            \"train\": transforms.Compose([\n",
    "                transforms.RandomResizedCrop(\n",
    "                    resize, scale=(0.5, 1.0)\n",
    "                ), # DataAug\n",
    "                transforms.RandomHorizontalFlip(), # DataAug\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            \"val\": transforms.Compose([\n",
    "                transforms.Resize(resize),\n",
    "                transforms.CenterCrop(resize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "    def __call__(self, img, phase=\"train\"):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase: 'train' or 'val'\n",
    "            前処理のモードを指定\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(phase=\"train\"):\n",
    "    \"\"\"\n",
    "    データのパスを格納したリストを作成する\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    phase: 'train' or 'val'\n",
    "        訓練データか検証データかを指定する\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    path_list: list\n",
    "        データへのパスを格納したリスト\n",
    "    \"\"\"\n",
    "    \n",
    "    rootpath = hymenoptera_path\n",
    "    target_path = osp.join(f\"{rootpath}/{phase}/**/*.jpg\")\n",
    "    print(target_path)\n",
    "    \n",
    "    path_list = []\n",
    "    for path in glob.glob(target_path):\n",
    "        path_list.append(path)\n",
    "    \n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HymenopteraDataset(data.Dataset): # PytorchのDatasetクラスを継承\n",
    "    \"\"\"\n",
    "    アリとハチの画像のDatasetクラス\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    file_list: リスト\n",
    "        画像のパスを格納したリスト\n",
    "    transform: object\n",
    "        前処理クラスのインスタンス\n",
    "    phase: 'train' or 'test'\n",
    "        学習データかテストデータかを指定する\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_list, transform=None, phase='train'):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        img_transformed = self.transform(img, self.phase)\n",
    "        \n",
    "        label = img_path.split(os.sep)[-2]\n",
    "        \n",
    "        if label == \"ants\":\n",
    "            label = 0\n",
    "        elif label == \"bees\":\n",
    "            label = 1\n",
    "        \n",
    "        return img_transformed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/chapter1/hymenoptera_data/train/**/*.jpg\n",
      "../datasets/chapter1/hymenoptera_data/val/**/*.jpg\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "size = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "transform = ImageTransform(size, mean, std)\n",
    "\n",
    "train_list = make_datapath_list(phase=\"train\")\n",
    "train_dataset = HymenopteraDataset(train_list, transform, \"train\")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "val_list = make_datapath_list(phase=\"val\")\n",
    "val_dataset = HymenopteraDataset(val_list, transform, \"val\")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "dataloaders_dict = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"val\": val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークモデルを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これも1-3と同じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG-16の学習済みモデルを使用\n",
    "net = models.vgg16(pretrained=True)\n",
    "\n",
    "# 2択の全結合層を加える\n",
    "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
    "\n",
    "# 訓練モード\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数を定義\n",
    "これも1-3と同じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化手法を設定\n",
    "転移学習とは異なり，全ての学習可能パラメータを再学習できるよう設定する  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_to_update_1に格納:  features.0.weight\n",
      "params_to_update_1に格納:  features.0.bias\n",
      "params_to_update_1に格納:  features.2.weight\n",
      "params_to_update_1に格納:  features.2.bias\n",
      "params_to_update_1に格納:  features.5.weight\n",
      "params_to_update_1に格納:  features.5.bias\n",
      "params_to_update_1に格納:  features.7.weight\n",
      "params_to_update_1に格納:  features.7.bias\n",
      "params_to_update_1に格納:  features.10.weight\n",
      "params_to_update_1に格納:  features.10.bias\n",
      "params_to_update_1に格納:  features.12.weight\n",
      "params_to_update_1に格納:  features.12.bias\n",
      "params_to_update_1に格納:  features.14.weight\n",
      "params_to_update_1に格納:  features.14.bias\n",
      "params_to_update_1に格納:  features.17.weight\n",
      "params_to_update_1に格納:  features.17.bias\n",
      "params_to_update_1に格納:  features.19.weight\n",
      "params_to_update_1に格納:  features.19.bias\n",
      "params_to_update_1に格納:  features.21.weight\n",
      "params_to_update_1に格納:  features.21.bias\n",
      "params_to_update_1に格納:  features.24.weight\n",
      "params_to_update_1に格納:  features.24.bias\n",
      "params_to_update_1に格納:  features.26.weight\n",
      "params_to_update_1に格納:  features.26.bias\n",
      "params_to_update_1に格納:  features.28.weight\n",
      "params_to_update_1に格納:  features.28.bias\n",
      "params_to_update_2に格納:  classifier.0.weight\n",
      "params_to_update_2に格納:  classifier.0.bias\n",
      "params_to_update_2に格納:  classifier.3.weight\n",
      "params_to_update_2に格納:  classifier.3.bias\n",
      "params_to_update_3に格納:  classifier.6.weight\n",
      "params_to_update_3に格納:  classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update_1 = []\n",
    "params_to_update_2 = []\n",
    "params_to_update_3 = []\n",
    "\n",
    "update_param_names_1 = [\n",
    "    \"features\"\n",
    "]\n",
    "update_param_names_2 = [\n",
    "    \"classifier.0.weight\",\n",
    "    \"classifier.0.bias\",\n",
    "    \"classifier.3.weight\",\n",
    "    \"classifier.3.bias\"\n",
    "]\n",
    "update_param_names_3 = [\n",
    "    \"classifier.6.weight\",\n",
    "    \"classifier.6.bias\"\n",
    "]\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if update_param_names_1[0] in name:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_1.append(param)\n",
    "        print(\"params_to_update_1に格納: \", name)\n",
    "    elif name in update_param_names_2:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_2.append(param)\n",
    "        print(\"params_to_update_2に格納: \", name)\n",
    "    elif name in update_param_names_3:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_3.append(param)\n",
    "        print(\"params_to_update_3に格納: \", name)\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        print(\"勾配計算なし， 学習しない: \", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最適化手法には，今回もMomentum SGDを用いる．  \n",
    "パラメータごとに最適化手法のパラメータを設定できる．  \n",
    "momentumは全て同じにするので外側に書いているが，個別に設定することも可能な模様"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([\n",
    "    {'params': params_to_update_1, 'lr': 1e-4},\n",
    "    {'params': params_to_update_2, 'lr': 5e-4},\n",
    "    {'params': params_to_update_3, 'lr': 1e-3},\n",
    "], momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習・検証を実施\n",
    "基本的に1-3と同じだが，GPUを使用できるようにしているところが異なる  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device(net, benchmark=True):\n",
    "    # GPUが使用可能ならば設定\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス: \", device)\n",
    "    \n",
    "    # ネットワークをGPUへ渡す\n",
    "    net.to(device)\n",
    "    \n",
    "    # ネットワークがある程度固定であれば，高速化できる\n",
    "    torch.backends.cudnn.benchmark = benchmark\n",
    "    \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-3とほぼ同様の関数だが，データをGPUへ送る必要がある\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs, device=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"--------------------\")\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            epoch_size = len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            # 未学習時の検証性能を確かめるため，最初の訓練は省略\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "            \n",
    "            # ミニバッチごとに学習を行う\n",
    "            # tqdm: means \"progress\" in Arabic (taqadum)\n",
    "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
    "                \n",
    "                # 使用可能デバイスがあるならデータを渡す\n",
    "                if device:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                    # 訓練時は誤差逆伝播で勾配を取得して重みの更新を行う\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    # ミニバッチのLossと正解数をepochのものに追加\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            # item一つごとの平均Lossと平均正解数\n",
    "            epoch_loss = epoch_loss / epoch_size\n",
    "            epoch_acc = epoch_corrects.double() / epoch_size\n",
    "            \n",
    "            # Epochのステータス\n",
    "            print(f'{phase} Loss: {epoch_loss} Acc: {epoch_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.65it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7703910294701072 Acc: 0.4444444444444445\n",
      "Epoch 2/2\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:06<00:00,  1.18it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4966980400399416 Acc: 0.7489711934156379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.17173519048815458 Acc: 0.9477124183006537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "device = set_device(net)\n",
    "train_model(\n",
    "    net=net, \n",
    "    dataloaders_dict=dataloaders_dict, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    num_epochs=num_epochs, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習したネットワークを保存・ロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path = osp.join(data_dir, \"weights_fine_tuning.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# セーブ, state_dictの返り値を保存\n",
    "torch.save(net.state_dict(), net_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ロード, GPUへ重みをあらかじめ渡すことができる\n",
    "if not torch.cuda.is_available():\n",
    "    weights = torch.load(net_path)\n",
    "else:\n",
    "    weights = torch.load(net_path, map_location={'cuda:0': 'cpu'})\n",
    "\n",
    "net.load_state_dict(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
