{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECOの実装と推論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KineticsのDataLoaderを作成\n",
    "前のnotebookで説明したDataLoaderの作成と動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from dataloader import make_datapath_list, get_label_id_dictionary\n",
    "from dataloader import VideoTransform, VideoDataset\n",
    "from eco import ECO_2D, ECO_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../../datasets/ptca_datasets/chapter9/kinetics_videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([16, 3, 224, 224])\n",
      "Label: bungee jumping\n",
      "Label ID: 40\n",
      "Movie Path: ../datasets/chapter9/kinetics_videos/bungee jumping/dAeUFSdYG1I_000010_000020\n"
     ]
    }
   ],
   "source": [
    "video_list = make_datapath_list(output_dir)\n",
    "\n",
    "# 前処理の設定\n",
    "resize, crop_size = 224, 224\n",
    "mean, std = [104, 117, 123], [1, 1, 1]\n",
    "video_transform = VideoTransform(resize, crop_size, mean, std)\n",
    "\n",
    "# ラベル名→IDのリストを取得\n",
    "label_dictionary_path = \"./kinetics_400_label_dictionary.csv\"\n",
    "label_id_dict, id_label_dict = get_label_id_dictionary(label_dictionary_path)\n",
    "\n",
    "# Datasetの作成\n",
    "val_dataset = VideoDataset(\n",
    "    video_list,\n",
    "    label_id_dict,\n",
    "    num_segments=16,\n",
    "    phase=\"val\",\n",
    "    transform=video_transform,\n",
    "    img_tmpl=\"image_{:05d}.jpg\"\n",
    ")\n",
    "\n",
    "# 動作確認\n",
    "index = 0\n",
    "item = val_dataset.__getitem__(index)\n",
    "print(\"Size:\", item[0].shape)\n",
    "print(\"Label:\", item[1])\n",
    "print(\"Label ID:\", item[2])\n",
    "print(\"Movie Path:\", item[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DatasetをDataLoaderにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "batch_iterator = iter(val_dataloader)\n",
    "\n",
    "# 動作確認\n",
    "imgs_transformeds, labels, label_ids, dir_path = next(batch_iterator)\n",
    "print(imgs_transformeds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECOモデルの実装\n",
    "2DNetと3DNetを利用してモデルを組み立てる  \n",
    "(8, 16, 3, 224, 224)→(128, 3, 224, 224)と変形し，2DNetで各フレーム画像を取り扱う  \n",
    "その出力を(128, 96, 28, 28)→(8, 16, 96, 28, 28)と，元の次元数に戻し，3DNetへ渡す  \n",
    "3DNetの出力(8, 512)を全結合層に渡してクラス分類を行う．  \n",
    "  \n",
    "ECOにはFull ECOとECO Liteがあるが，ここではECO Liteを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECO_Lite(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECO_Lite, self).__init__()\n",
    "        \n",
    "        self.eco_2d = ECO_2D()\n",
    "        self.eco_3d = ECO_3D()\n",
    "        self.fc_final = nn.Linear(in_features=512, out_features=400, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input (M, 16, 3, 224, 224)\n",
    "        \"\"\"\n",
    "        \n",
    "        bs, ns, c, h, w = x.shape\n",
    "        \n",
    "        # ECO2Dは時間方向を考慮していないためバッチに押し込んでもよい\n",
    "        out = x.view(-1, c, h, w) \n",
    "        out = self.eco_2d(out)\n",
    "        \n",
    "        # ECO3Dに入れる前に動画ごとにフレームが分離される\n",
    "        out = out.view(-1, ns, 96, 28, 28)\n",
    "        out = self.eco_3d(out)\n",
    "        out = self.fc_final(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECO_Lite(\n",
       "  (eco_2d): ECO_2D(\n",
       "    (basic_conv): BasicConv(\n",
       "      (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1_relu_7x7): ReLU(inplace)\n",
       "      (pool1_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_relu_3x3_reduce): ReLU(inplace)\n",
       "      (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_relu_3x3): ReLU(inplace)\n",
       "      (pool2_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    )\n",
       "    (inceptionA): InceptionA(\n",
       "      (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_1x1): ReLU(inplace)\n",
       "      (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_3x3): ReLU(inplace)\n",
       "      (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_double_relu_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_double_relu_3x3_1): ReLU(inplace)\n",
       "      (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_double_relu_3x3_2): ReLU(inplace)\n",
       "      (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_pool_proj): ReLU(inplace)\n",
       "    )\n",
       "    (inceptionB): InceptionB(\n",
       "      (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_1x1): ReLU(inplace)\n",
       "      (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_3x3): ReLU(inplace)\n",
       "      (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_double_relu_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_double_relu_3x3_1): ReLU(inplace)\n",
       "      (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_double_relu_3x3_2): ReLU(inplace)\n",
       "      (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_pool_proj): ReLU(inplace)\n",
       "    )\n",
       "    (inceptionC): InceptionC(\n",
       "      (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3c_double_relu_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3c_double_relu_3x3_1): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (eco_3d): ECO_3D(\n",
       "    (res_3d_3): Resnet_3D_3(\n",
       "      (res3a_2): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res3a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res3a_relu): ReLU(inplace)\n",
       "      (res3b_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res3b_1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res3b_1_relu): ReLU(inplace)\n",
       "      (res3b_2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res3b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res3b_relu): ReLU(inplace)\n",
       "    )\n",
       "    (res_3d_4): Resnet_3D_4(\n",
       "      (res4a_1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res4a_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4a_1_relu): ReLU(inplace)\n",
       "      (res4a_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res4a_down): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res4a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4a_relu): ReLU(inplace)\n",
       "      (res4b_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res4b_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4b_1_relu): ReLU(inplace)\n",
       "      (res4b_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res4b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4b_relu): ReLU(inplace)\n",
       "    )\n",
       "    (res_3d_5): Resnet_3D_5(\n",
       "      (res5a_1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res5a_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5a_1_relu): ReLU(inplace)\n",
       "      (res5a_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res5a_down): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res5a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5a_relu): ReLU(inplace)\n",
       "      (res5b_1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res5b_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5b_1_relu): ReLU(inplace)\n",
       "      (res5b_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res5b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5b_relu): ReLU(inplace)\n",
       "    )\n",
       "    (global_pool): AvgPool3d(kernel_size=(4, 7, 7), stride=1, padding=0)\n",
       "  )\n",
       "  (fc_final): Linear(in_features=512, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ECO_Lite()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルをロード\n",
    "これを訓練すると異常に時間がかかるため，転移学習する  \n",
    "[ECO_Lite_rgb_model_Kinetics.pth.tar](https://drive.google.com/file/d/1XNIq7byciKgrn011jLBggd2g79jKX4uD/view)をload_weights.shで取得．  \n",
    "参考：[curlやwgetで公開済みGoogle Driveデータをダウンロードする](https://qiita.com/namakemono/items/c963e75e0af3f7eed732)  \n",
    "  \n",
    "順番が対応していれば正しい重みデータが上書きされる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_ECO(model_dict, pretrained_model_dict):\n",
    "    param_names = []\n",
    "    for name, param in model_dict.items():\n",
    "        param_names.append(name)\n",
    "        \n",
    "    new_state_dict = model_dict.copy()\n",
    "    \n",
    "    for index, (key_name, value) in enumerate(pretrained_model_dict.items()):\n",
    "        name = param_names[index]\n",
    "        new_state_dict[name] = value\n",
    "        print(f\"{key_name} → {name}\")\n",
    "    \n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module.base_model.conv1_7x7_s2.weight → eco_2d.basic_conv.conv1_7x7_s2.weight\n",
      "module.base_model.conv1_7x7_s2.bias → eco_2d.basic_conv.conv1_7x7_s2.bias\n",
      "module.base_model.conv1_7x7_s2_bn.weight → eco_2d.basic_conv.conv1_7x7_s2_bn.weight\n",
      "module.base_model.conv1_7x7_s2_bn.bias → eco_2d.basic_conv.conv1_7x7_s2_bn.bias\n",
      "module.base_model.conv1_7x7_s2_bn.running_mean → eco_2d.basic_conv.conv1_7x7_s2_bn.running_mean\n",
      "module.base_model.conv1_7x7_s2_bn.running_var → eco_2d.basic_conv.conv1_7x7_s2_bn.running_var\n",
      "module.base_model.conv1_7x7_s2_bn.num_batches_tracked → eco_2d.basic_conv.conv1_7x7_s2_bn.num_batches_tracked\n",
      "module.base_model.conv2_3x3_reduce.weight → eco_2d.basic_conv.conv2_3x3_reduce.weight\n",
      "module.base_model.conv2_3x3_reduce.bias → eco_2d.basic_conv.conv2_3x3_reduce.bias\n",
      "module.base_model.conv2_3x3_reduce_bn.weight → eco_2d.basic_conv.conv2_3x3_reduce_bn.weight\n",
      "module.base_model.conv2_3x3_reduce_bn.bias → eco_2d.basic_conv.conv2_3x3_reduce_bn.bias\n",
      "module.base_model.conv2_3x3_reduce_bn.running_mean → eco_2d.basic_conv.conv2_3x3_reduce_bn.running_mean\n",
      "module.base_model.conv2_3x3_reduce_bn.running_var → eco_2d.basic_conv.conv2_3x3_reduce_bn.running_var\n",
      "module.base_model.conv2_3x3_reduce_bn.num_batches_tracked → eco_2d.basic_conv.conv2_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.conv2_3x3.weight → eco_2d.basic_conv.conv2_3x3.weight\n",
      "module.base_model.conv2_3x3.bias → eco_2d.basic_conv.conv2_3x3.bias\n",
      "module.base_model.conv2_3x3_bn.weight → eco_2d.basic_conv.conv2_3x3_bn.weight\n",
      "module.base_model.conv2_3x3_bn.bias → eco_2d.basic_conv.conv2_3x3_bn.bias\n",
      "module.base_model.conv2_3x3_bn.running_mean → eco_2d.basic_conv.conv2_3x3_bn.running_mean\n",
      "module.base_model.conv2_3x3_bn.running_var → eco_2d.basic_conv.conv2_3x3_bn.running_var\n",
      "module.base_model.conv2_3x3_bn.num_batches_tracked → eco_2d.basic_conv.conv2_3x3_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_1x1.weight → eco_2d.inceptionA.inception_3a_1x1.weight\n",
      "module.base_model.inception_3a_1x1.bias → eco_2d.inceptionA.inception_3a_1x1.bias\n",
      "module.base_model.inception_3a_1x1_bn.weight → eco_2d.inceptionA.inception_3a_1x1_bn.weight\n",
      "module.base_model.inception_3a_1x1_bn.bias → eco_2d.inceptionA.inception_3a_1x1_bn.bias\n",
      "module.base_model.inception_3a_1x1_bn.running_mean → eco_2d.inceptionA.inception_3a_1x1_bn.running_mean\n",
      "module.base_model.inception_3a_1x1_bn.running_var → eco_2d.inceptionA.inception_3a_1x1_bn.running_var\n",
      "module.base_model.inception_3a_1x1_bn.num_batches_tracked → eco_2d.inceptionA.inception_3a_1x1_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_3x3_reduce.weight → eco_2d.inceptionA.inception_3a_3x3_reduce.weight\n",
      "module.base_model.inception_3a_3x3_reduce.bias → eco_2d.inceptionA.inception_3a_3x3_reduce.bias\n",
      "module.base_model.inception_3a_3x3_reduce_bn.weight → eco_2d.inceptionA.inception_3a_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3a_3x3_reduce_bn.bias → eco_2d.inceptionA.inception_3a_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3a_3x3_reduce_bn.running_mean → eco_2d.inceptionA.inception_3a_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3a_3x3_reduce_bn.running_var → eco_2d.inceptionA.inception_3a_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3a_3x3_reduce_bn.num_batches_tracked → eco_2d.inceptionA.inception_3a_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_3x3.weight → eco_2d.inceptionA.inception_3a_3x3.weight\n",
      "module.base_model.inception_3a_3x3.bias → eco_2d.inceptionA.inception_3a_3x3.bias\n",
      "module.base_model.inception_3a_3x3_bn.weight → eco_2d.inceptionA.inception_3a_3x3_bn.weight\n",
      "module.base_model.inception_3a_3x3_bn.bias → eco_2d.inceptionA.inception_3a_3x3_bn.bias\n",
      "module.base_model.inception_3a_3x3_bn.running_mean → eco_2d.inceptionA.inception_3a_3x3_bn.running_mean\n",
      "module.base_model.inception_3a_3x3_bn.running_var → eco_2d.inceptionA.inception_3a_3x3_bn.running_var\n",
      "module.base_model.inception_3a_3x3_bn.num_batches_tracked → eco_2d.inceptionA.inception_3a_3x3_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_double_3x3_reduce.weight → eco_2d.inceptionA.inception_3a_double_3x3_reduce.weight\n",
      "module.base_model.inception_3a_double_3x3_reduce.bias → eco_2d.inceptionA.inception_3a_double_3x3_reduce.bias\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.weight → eco_2d.inceptionA.inception_3a_double_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.bias → eco_2d.inceptionA.inception_3a_double_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.running_mean → eco_2d.inceptionA.inception_3a_double_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.running_var → eco_2d.inceptionA.inception_3a_double_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.num_batches_tracked → eco_2d.inceptionA.inception_3a_double_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_double_3x3_1.weight → eco_2d.inceptionA.inception_3a_double_3x3_1.weight\n",
      "module.base_model.inception_3a_double_3x3_1.bias → eco_2d.inceptionA.inception_3a_double_3x3_1.bias\n",
      "module.base_model.inception_3a_double_3x3_1_bn.weight → eco_2d.inceptionA.inception_3a_double_3x3_1_bn.weight\n",
      "module.base_model.inception_3a_double_3x3_1_bn.bias → eco_2d.inceptionA.inception_3a_double_3x3_1_bn.bias\n",
      "module.base_model.inception_3a_double_3x3_1_bn.running_mean → eco_2d.inceptionA.inception_3a_double_3x3_1_bn.running_mean\n",
      "module.base_model.inception_3a_double_3x3_1_bn.running_var → eco_2d.inceptionA.inception_3a_double_3x3_1_bn.running_var\n",
      "module.base_model.inception_3a_double_3x3_1_bn.num_batches_tracked → eco_2d.inceptionA.inception_3a_double_3x3_1_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_double_3x3_2.weight → eco_2d.inceptionA.inception_3a_double_3x3_2.weight\n",
      "module.base_model.inception_3a_double_3x3_2.bias → eco_2d.inceptionA.inception_3a_double_3x3_2.bias\n",
      "module.base_model.inception_3a_double_3x3_2_bn.weight → eco_2d.inceptionA.inception_3a_double_3x3_2_bn.weight\n",
      "module.base_model.inception_3a_double_3x3_2_bn.bias → eco_2d.inceptionA.inception_3a_double_3x3_2_bn.bias\n",
      "module.base_model.inception_3a_double_3x3_2_bn.running_mean → eco_2d.inceptionA.inception_3a_double_3x3_2_bn.running_mean\n",
      "module.base_model.inception_3a_double_3x3_2_bn.running_var → eco_2d.inceptionA.inception_3a_double_3x3_2_bn.running_var\n",
      "module.base_model.inception_3a_double_3x3_2_bn.num_batches_tracked → eco_2d.inceptionA.inception_3a_double_3x3_2_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_pool_proj.weight → eco_2d.inceptionA.inception_3a_pool_proj.weight\n",
      "module.base_model.inception_3a_pool_proj.bias → eco_2d.inceptionA.inception_3a_pool_proj.bias\n",
      "module.base_model.inception_3a_pool_proj_bn.weight → eco_2d.inceptionA.inception_3a_pool_proj_bn.weight\n",
      "module.base_model.inception_3a_pool_proj_bn.bias → eco_2d.inceptionA.inception_3a_pool_proj_bn.bias\n",
      "module.base_model.inception_3a_pool_proj_bn.running_mean → eco_2d.inceptionA.inception_3a_pool_proj_bn.running_mean\n",
      "module.base_model.inception_3a_pool_proj_bn.running_var → eco_2d.inceptionA.inception_3a_pool_proj_bn.running_var\n",
      "module.base_model.inception_3a_pool_proj_bn.num_batches_tracked → eco_2d.inceptionA.inception_3a_pool_proj_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_1x1.weight → eco_2d.inceptionB.inception_3b_1x1.weight\n",
      "module.base_model.inception_3b_1x1.bias → eco_2d.inceptionB.inception_3b_1x1.bias\n",
      "module.base_model.inception_3b_1x1_bn.weight → eco_2d.inceptionB.inception_3b_1x1_bn.weight\n",
      "module.base_model.inception_3b_1x1_bn.bias → eco_2d.inceptionB.inception_3b_1x1_bn.bias\n",
      "module.base_model.inception_3b_1x1_bn.running_mean → eco_2d.inceptionB.inception_3b_1x1_bn.running_mean\n",
      "module.base_model.inception_3b_1x1_bn.running_var → eco_2d.inceptionB.inception_3b_1x1_bn.running_var\n",
      "module.base_model.inception_3b_1x1_bn.num_batches_tracked → eco_2d.inceptionB.inception_3b_1x1_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_3x3_reduce.weight → eco_2d.inceptionB.inception_3b_3x3_reduce.weight\n",
      "module.base_model.inception_3b_3x3_reduce.bias → eco_2d.inceptionB.inception_3b_3x3_reduce.bias\n",
      "module.base_model.inception_3b_3x3_reduce_bn.weight → eco_2d.inceptionB.inception_3b_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3b_3x3_reduce_bn.bias → eco_2d.inceptionB.inception_3b_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3b_3x3_reduce_bn.running_mean → eco_2d.inceptionB.inception_3b_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3b_3x3_reduce_bn.running_var → eco_2d.inceptionB.inception_3b_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3b_3x3_reduce_bn.num_batches_tracked → eco_2d.inceptionB.inception_3b_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_3x3.weight → eco_2d.inceptionB.inception_3b_3x3.weight\n",
      "module.base_model.inception_3b_3x3.bias → eco_2d.inceptionB.inception_3b_3x3.bias\n",
      "module.base_model.inception_3b_3x3_bn.weight → eco_2d.inceptionB.inception_3b_3x3_bn.weight\n",
      "module.base_model.inception_3b_3x3_bn.bias → eco_2d.inceptionB.inception_3b_3x3_bn.bias\n",
      "module.base_model.inception_3b_3x3_bn.running_mean → eco_2d.inceptionB.inception_3b_3x3_bn.running_mean\n",
      "module.base_model.inception_3b_3x3_bn.running_var → eco_2d.inceptionB.inception_3b_3x3_bn.running_var\n",
      "module.base_model.inception_3b_3x3_bn.num_batches_tracked → eco_2d.inceptionB.inception_3b_3x3_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_double_3x3_reduce.weight → eco_2d.inceptionB.inception_3b_double_3x3_reduce.weight\n",
      "module.base_model.inception_3b_double_3x3_reduce.bias → eco_2d.inceptionB.inception_3b_double_3x3_reduce.bias\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.weight → eco_2d.inceptionB.inception_3b_double_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.bias → eco_2d.inceptionB.inception_3b_double_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.running_mean → eco_2d.inceptionB.inception_3b_double_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.running_var → eco_2d.inceptionB.inception_3b_double_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.num_batches_tracked → eco_2d.inceptionB.inception_3b_double_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_double_3x3_1.weight → eco_2d.inceptionB.inception_3b_double_3x3_1.weight\n",
      "module.base_model.inception_3b_double_3x3_1.bias → eco_2d.inceptionB.inception_3b_double_3x3_1.bias\n",
      "module.base_model.inception_3b_double_3x3_1_bn.weight → eco_2d.inceptionB.inception_3b_double_3x3_1_bn.weight\n",
      "module.base_model.inception_3b_double_3x3_1_bn.bias → eco_2d.inceptionB.inception_3b_double_3x3_1_bn.bias\n",
      "module.base_model.inception_3b_double_3x3_1_bn.running_mean → eco_2d.inceptionB.inception_3b_double_3x3_1_bn.running_mean\n",
      "module.base_model.inception_3b_double_3x3_1_bn.running_var → eco_2d.inceptionB.inception_3b_double_3x3_1_bn.running_var\n",
      "module.base_model.inception_3b_double_3x3_1_bn.num_batches_tracked → eco_2d.inceptionB.inception_3b_double_3x3_1_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_double_3x3_2.weight → eco_2d.inceptionB.inception_3b_double_3x3_2.weight\n",
      "module.base_model.inception_3b_double_3x3_2.bias → eco_2d.inceptionB.inception_3b_double_3x3_2.bias\n",
      "module.base_model.inception_3b_double_3x3_2_bn.weight → eco_2d.inceptionB.inception_3b_double_3x3_2_bn.weight\n",
      "module.base_model.inception_3b_double_3x3_2_bn.bias → eco_2d.inceptionB.inception_3b_double_3x3_2_bn.bias\n",
      "module.base_model.inception_3b_double_3x3_2_bn.running_mean → eco_2d.inceptionB.inception_3b_double_3x3_2_bn.running_mean\n",
      "module.base_model.inception_3b_double_3x3_2_bn.running_var → eco_2d.inceptionB.inception_3b_double_3x3_2_bn.running_var\n",
      "module.base_model.inception_3b_double_3x3_2_bn.num_batches_tracked → eco_2d.inceptionB.inception_3b_double_3x3_2_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_pool_proj.weight → eco_2d.inceptionB.inception_3b_pool_proj.weight\n",
      "module.base_model.inception_3b_pool_proj.bias → eco_2d.inceptionB.inception_3b_pool_proj.bias\n",
      "module.base_model.inception_3b_pool_proj_bn.weight → eco_2d.inceptionB.inception_3b_pool_proj_bn.weight\n",
      "module.base_model.inception_3b_pool_proj_bn.bias → eco_2d.inceptionB.inception_3b_pool_proj_bn.bias\n",
      "module.base_model.inception_3b_pool_proj_bn.running_mean → eco_2d.inceptionB.inception_3b_pool_proj_bn.running_mean\n",
      "module.base_model.inception_3b_pool_proj_bn.running_var → eco_2d.inceptionB.inception_3b_pool_proj_bn.running_var\n",
      "module.base_model.inception_3b_pool_proj_bn.num_batches_tracked → eco_2d.inceptionB.inception_3b_pool_proj_bn.num_batches_tracked\n",
      "module.base_model.inception_3c_double_3x3_reduce.weight → eco_2d.inceptionC.inception_3c_double_3x3_reduce.weight\n",
      "module.base_model.inception_3c_double_3x3_reduce.bias → eco_2d.inceptionC.inception_3c_double_3x3_reduce.bias\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.weight → eco_2d.inceptionC.inception_3c_double_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.bias → eco_2d.inceptionC.inception_3c_double_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.running_mean → eco_2d.inceptionC.inception_3c_double_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.running_var → eco_2d.inceptionC.inception_3c_double_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.num_batches_tracked → eco_2d.inceptionC.inception_3c_double_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3c_double_3x3_1.weight → eco_2d.inceptionC.inception_3c_double_3x3_1.weight\n",
      "module.base_model.inception_3c_double_3x3_1.bias → eco_2d.inceptionC.inception_3c_double_3x3_1.bias\n",
      "module.base_model.inception_3c_double_3x3_1_bn.weight → eco_2d.inceptionC.inception_3c_double_3x3_1_bn.weight\n",
      "module.base_model.inception_3c_double_3x3_1_bn.bias → eco_2d.inceptionC.inception_3c_double_3x3_1_bn.bias\n",
      "module.base_model.inception_3c_double_3x3_1_bn.running_mean → eco_2d.inceptionC.inception_3c_double_3x3_1_bn.running_mean\n",
      "module.base_model.inception_3c_double_3x3_1_bn.running_var → eco_2d.inceptionC.inception_3c_double_3x3_1_bn.running_var\n",
      "module.base_model.inception_3c_double_3x3_1_bn.num_batches_tracked → eco_2d.inceptionC.inception_3c_double_3x3_1_bn.num_batches_tracked\n",
      "module.base_model.res3a_2.weight → eco_3d.res_3d_3.res3a_2.weight\n",
      "module.base_model.res3a_2.bias → eco_3d.res_3d_3.res3a_2.bias\n",
      "module.base_model.res3a_bn.weight → eco_3d.res_3d_3.res3a_bn.weight\n",
      "module.base_model.res3a_bn.bias → eco_3d.res_3d_3.res3a_bn.bias\n",
      "module.base_model.res3a_bn.running_mean → eco_3d.res_3d_3.res3a_bn.running_mean\n",
      "module.base_model.res3a_bn.running_var → eco_3d.res_3d_3.res3a_bn.running_var\n",
      "module.base_model.res3a_bn.num_batches_tracked → eco_3d.res_3d_3.res3a_bn.num_batches_tracked\n",
      "module.base_model.res3b_1.weight → eco_3d.res_3d_3.res3b_1.weight\n",
      "module.base_model.res3b_1.bias → eco_3d.res_3d_3.res3b_1.bias\n",
      "module.base_model.res3b_1_bn.weight → eco_3d.res_3d_3.res3b_1_bn.weight\n",
      "module.base_model.res3b_1_bn.bias → eco_3d.res_3d_3.res3b_1_bn.bias\n",
      "module.base_model.res3b_1_bn.running_mean → eco_3d.res_3d_3.res3b_1_bn.running_mean\n",
      "module.base_model.res3b_1_bn.running_var → eco_3d.res_3d_3.res3b_1_bn.running_var\n",
      "module.base_model.res3b_1_bn.num_batches_tracked → eco_3d.res_3d_3.res3b_1_bn.num_batches_tracked\n",
      "module.base_model.res3b_2.weight → eco_3d.res_3d_3.res3b_2.weight\n",
      "module.base_model.res3b_2.bias → eco_3d.res_3d_3.res3b_2.bias\n",
      "module.base_model.res3b_bn.weight → eco_3d.res_3d_3.res3b_bn.weight\n",
      "module.base_model.res3b_bn.bias → eco_3d.res_3d_3.res3b_bn.bias\n",
      "module.base_model.res3b_bn.running_mean → eco_3d.res_3d_3.res3b_bn.running_mean\n",
      "module.base_model.res3b_bn.running_var → eco_3d.res_3d_3.res3b_bn.running_var\n",
      "module.base_model.res3b_bn.num_batches_tracked → eco_3d.res_3d_3.res3b_bn.num_batches_tracked\n",
      "module.base_model.res4a_1.weight → eco_3d.res_3d_4.res4a_1.weight\n",
      "module.base_model.res4a_1.bias → eco_3d.res_3d_4.res4a_1.bias\n",
      "module.base_model.res4a_1_bn.weight → eco_3d.res_3d_4.res4a_1_bn.weight\n",
      "module.base_model.res4a_1_bn.bias → eco_3d.res_3d_4.res4a_1_bn.bias\n",
      "module.base_model.res4a_1_bn.running_mean → eco_3d.res_3d_4.res4a_1_bn.running_mean\n",
      "module.base_model.res4a_1_bn.running_var → eco_3d.res_3d_4.res4a_1_bn.running_var\n",
      "module.base_model.res4a_1_bn.num_batches_tracked → eco_3d.res_3d_4.res4a_1_bn.num_batches_tracked\n",
      "module.base_model.res4a_2.weight → eco_3d.res_3d_4.res4a_2.weight\n",
      "module.base_model.res4a_2.bias → eco_3d.res_3d_4.res4a_2.bias\n",
      "module.base_model.res4a_down.weight → eco_3d.res_3d_4.res4a_down.weight\n",
      "module.base_model.res4a_down.bias → eco_3d.res_3d_4.res4a_down.bias\n",
      "module.base_model.res4a_bn.weight → eco_3d.res_3d_4.res4a_bn.weight\n",
      "module.base_model.res4a_bn.bias → eco_3d.res_3d_4.res4a_bn.bias\n",
      "module.base_model.res4a_bn.running_mean → eco_3d.res_3d_4.res4a_bn.running_mean\n",
      "module.base_model.res4a_bn.running_var → eco_3d.res_3d_4.res4a_bn.running_var\n",
      "module.base_model.res4a_bn.num_batches_tracked → eco_3d.res_3d_4.res4a_bn.num_batches_tracked\n",
      "module.base_model.res4b_1.weight → eco_3d.res_3d_4.res4b_1.weight\n",
      "module.base_model.res4b_1.bias → eco_3d.res_3d_4.res4b_1.bias\n",
      "module.base_model.res4b_1_bn.weight → eco_3d.res_3d_4.res4b_1_bn.weight\n",
      "module.base_model.res4b_1_bn.bias → eco_3d.res_3d_4.res4b_1_bn.bias\n",
      "module.base_model.res4b_1_bn.running_mean → eco_3d.res_3d_4.res4b_1_bn.running_mean\n",
      "module.base_model.res4b_1_bn.running_var → eco_3d.res_3d_4.res4b_1_bn.running_var\n",
      "module.base_model.res4b_1_bn.num_batches_tracked → eco_3d.res_3d_4.res4b_1_bn.num_batches_tracked\n",
      "module.base_model.res4b_2.weight → eco_3d.res_3d_4.res4b_2.weight\n",
      "module.base_model.res4b_2.bias → eco_3d.res_3d_4.res4b_2.bias\n",
      "module.base_model.res4b_bn.weight → eco_3d.res_3d_4.res4b_bn.weight\n",
      "module.base_model.res4b_bn.bias → eco_3d.res_3d_4.res4b_bn.bias\n",
      "module.base_model.res4b_bn.running_mean → eco_3d.res_3d_4.res4b_bn.running_mean\n",
      "module.base_model.res4b_bn.running_var → eco_3d.res_3d_4.res4b_bn.running_var\n",
      "module.base_model.res4b_bn.num_batches_tracked → eco_3d.res_3d_4.res4b_bn.num_batches_tracked\n",
      "module.base_model.res5a_1.weight → eco_3d.res_3d_5.res5a_1.weight\n",
      "module.base_model.res5a_1.bias → eco_3d.res_3d_5.res5a_1.bias\n",
      "module.base_model.res5a_1_bn.weight → eco_3d.res_3d_5.res5a_1_bn.weight\n",
      "module.base_model.res5a_1_bn.bias → eco_3d.res_3d_5.res5a_1_bn.bias\n",
      "module.base_model.res5a_1_bn.running_mean → eco_3d.res_3d_5.res5a_1_bn.running_mean\n",
      "module.base_model.res5a_1_bn.running_var → eco_3d.res_3d_5.res5a_1_bn.running_var\n",
      "module.base_model.res5a_1_bn.num_batches_tracked → eco_3d.res_3d_5.res5a_1_bn.num_batches_tracked\n",
      "module.base_model.res5a_2.weight → eco_3d.res_3d_5.res5a_2.weight\n",
      "module.base_model.res5a_2.bias → eco_3d.res_3d_5.res5a_2.bias\n",
      "module.base_model.res5a_down.weight → eco_3d.res_3d_5.res5a_down.weight\n",
      "module.base_model.res5a_down.bias → eco_3d.res_3d_5.res5a_down.bias\n",
      "module.base_model.res5a_bn.weight → eco_3d.res_3d_5.res5a_bn.weight\n",
      "module.base_model.res5a_bn.bias → eco_3d.res_3d_5.res5a_bn.bias\n",
      "module.base_model.res5a_bn.running_mean → eco_3d.res_3d_5.res5a_bn.running_mean\n",
      "module.base_model.res5a_bn.running_var → eco_3d.res_3d_5.res5a_bn.running_var\n",
      "module.base_model.res5a_bn.num_batches_tracked → eco_3d.res_3d_5.res5a_bn.num_batches_tracked\n",
      "module.base_model.res5b_1.weight → eco_3d.res_3d_5.res5b_1.weight\n",
      "module.base_model.res5b_1.bias → eco_3d.res_3d_5.res5b_1.bias\n",
      "module.base_model.res5b_1_bn.weight → eco_3d.res_3d_5.res5b_1_bn.weight\n",
      "module.base_model.res5b_1_bn.bias → eco_3d.res_3d_5.res5b_1_bn.bias\n",
      "module.base_model.res5b_1_bn.running_mean → eco_3d.res_3d_5.res5b_1_bn.running_mean\n",
      "module.base_model.res5b_1_bn.running_var → eco_3d.res_3d_5.res5b_1_bn.running_var\n",
      "module.base_model.res5b_1_bn.num_batches_tracked → eco_3d.res_3d_5.res5b_1_bn.num_batches_tracked\n",
      "module.base_model.res5b_2.weight → eco_3d.res_3d_5.res5b_2.weight\n",
      "module.base_model.res5b_2.bias → eco_3d.res_3d_5.res5b_2.bias\n",
      "module.base_model.res5b_bn.weight → eco_3d.res_3d_5.res5b_bn.weight\n",
      "module.base_model.res5b_bn.bias → eco_3d.res_3d_5.res5b_bn.bias\n",
      "module.base_model.res5b_bn.running_mean → eco_3d.res_3d_5.res5b_bn.running_mean\n",
      "module.base_model.res5b_bn.running_var → eco_3d.res_3d_5.res5b_bn.running_var\n",
      "module.base_model.res5b_bn.num_batches_tracked → eco_3d.res_3d_5.res5b_bn.num_batches_tracked\n",
      "module.new_fc.weight → fc_final.weight\n",
      "module.new_fc.bias → fc_final.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_model_ECO = \"../datasets/chapter9/ECO_Lite_rgb_model_Kinetics.pth.tar\"\n",
    "pretrained_model = torch.load(net_model_ECO, map_location='cpu')\n",
    "pretrained_model_dict = pretrained_model['state_dict']\n",
    "\n",
    "model_dict = net.state_dict()\n",
    "\n",
    "new_state_dict = load_pretrained_ECO(model_dict, pretrained_model_dict)\n",
    "\n",
    "net.eval()\n",
    "net.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論\n",
    "DataLoaderから8つの動画を取り出し，それぞれECOモデルで推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 400])\n"
     ]
    }
   ],
   "source": [
    "batch_iterator = iter(val_dataloader)\n",
    "imgs_transformeds, labels, label_ids, dir_path = next(batch_iterator)\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    outputs = net(imgs_transformeds)\n",
    "\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論結果の上位を出力する処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dir_path, outputs_input, id_label_dict, idx=0):\n",
    "    print(\"Path:\", dir_path[idx])\n",
    "    \n",
    "    outputs = outputs_input.clone()\n",
    "    \n",
    "    for i in range(5):\n",
    "        output = outputs[idx]\n",
    "        _, pred = torch.max(output, dim=0)\n",
    "        class_idx = int(pred.numpy())\n",
    "        print(f\"Rank {i+1}: {id_label_dict[class_idx]}\")\n",
    "        outputs[idx][class_idx] = -1000 # 最大値だったものを消す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: ../datasets/chapter9/kinetics_videos/bungee jumping/TUvSX0pYu4o_000002_000012\n",
      "Rank 1: bungee jumping\n",
      "Rank 2: trapezing\n",
      "Rank 3: abseiling\n",
      "Rank 4: swinging on something\n",
      "Rank 5: climbing a rope\n"
     ]
    }
   ],
   "source": [
    "inference(dir_path, outputs, id_label_dict, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バンジージャンプと推定成功  \n",
    "2位は空中ブランコ，3位は懸垂下降で，確かに雰囲気がバンジージャンプに似ているかもしれない．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: ../datasets/chapter9/kinetics_videos/arm wrestling/BdMiTo_OtnU_000024_000034\n",
      "Rank 1: arm wrestling\n",
      "Rank 2: drinking beer\n",
      "Rank 3: getting a tattoo\n",
      "Rank 4: waxing legs\n",
      "Rank 5: stretching leg\n"
     ]
    }
   ],
   "source": [
    "inference(dir_path, outputs, id_label_dict, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アームレスリングも成功  \n",
    "ビールを飲むときにも確かに腕を豪快に使うので似た雰囲気かもしれない．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに自前のデータセットでファインチューニングしていくことで自前の動画でも分類が可能になる．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
